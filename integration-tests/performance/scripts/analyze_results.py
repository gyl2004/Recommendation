#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½å†…å®¹æ¨èå¹³å°æ€§èƒ½æµ‹è¯•ç»“æœåˆ†æè„šæœ¬
"""

import sys
import csv
import json
import statistics
from datetime import datetime
from collections import defaultdict, Counter

class PerformanceAnalyzer:
    def __init__(self, jtl_file):
        self.jtl_file = jtl_file
        self.results = []
        self.load_results()
    
    def load_results(self):
        """åŠ è½½JTLæµ‹è¯•ç»“æœæ–‡ä»¶"""
        try:
            with open(self.jtl_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    self.results.append({
                        'timestamp': int(row['timeStamp']),
                        'elapsed': int(row['elapsed']),
                        'label': row['label'],
                        'responseCode': row['responseCode'],
                        'success': row['success'] == 'true',
                        'bytes': int(row.get('bytes', 0)),
                        'sentBytes': int(row.get('sentBytes', 0)),
                        'latency': int(row.get('Latency', 0)),
                        'connect': int(row.get('Connect', 0))
                    })
            print(f"æˆåŠŸåŠ è½½ {len(self.results)} æ¡æµ‹è¯•ç»“æœ")
        except Exception as e:
            print(f"åŠ è½½ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    def calculate_basic_stats(self):
        """è®¡ç®—åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        if not self.results:
            return {}
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [r['elapsed'] for r in self.results]
        success_count = sum(1 for r in self.results if r['success'])
        error_count = len(self.results) - success_count
        
        # è®¡ç®—QPS
        if self.results:
            start_time = min(r['timestamp'] for r in self.results)
            end_time = max(r['timestamp'] for r in self.results)
            duration_seconds = (end_time - start_time) / 1000.0
            qps = len(self.results) / duration_seconds if duration_seconds > 0 else 0
        else:
            qps = 0
        
        stats = {
            'total_requests': len(self.results),
            'success_requests': success_count,
            'error_requests': error_count,
            'success_rate': (success_count / len(self.results)) * 100,
            'error_rate': (error_count / len(self.results)) * 100,
            'qps': qps,
            'avg_response_time': statistics.mean(response_times),
            'median_response_time': statistics.median(response_times),
            'min_response_time': min(response_times),
            'max_response_time': max(response_times),
            'p95_response_time': self.percentile(response_times, 95),
            'p99_response_time': self.percentile(response_times, 99),
            'std_response_time': statistics.stdev(response_times) if len(response_times) > 1 else 0
        }
        
        return stats
    
    def percentile(self, data, percentile):
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int((percentile / 100.0) * len(sorted_data))
        if index >= len(sorted_data):
            index = len(sorted_data) - 1
        return sorted_data[index]
    
    def analyze_by_endpoint(self):
        """æŒ‰æ¥å£åˆ†ææ€§èƒ½"""
        endpoint_stats = defaultdict(list)
        
        for result in self.results:
            endpoint_stats[result['label']].append(result)
        
        analysis = {}
        for endpoint, results in endpoint_stats.items():
            response_times = [r['elapsed'] for r in results]
            success_count = sum(1 for r in results if r['success'])
            
            analysis[endpoint] = {
                'total_requests': len(results),
                'success_requests': success_count,
                'success_rate': (success_count / len(results)) * 100,
                'avg_response_time': statistics.mean(response_times),
                'p95_response_time': self.percentile(response_times, 95),
                'p99_response_time': self.percentile(response_times, 99),
                'max_response_time': max(response_times),
                'min_response_time': min(response_times)
            }
        
        return analysis
    
    def analyze_error_patterns(self):
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        error_results = [r for r in self.results if not r['success']]
        
        if not error_results:
            return {'total_errors': 0, 'error_patterns': {}}
        
        # æŒ‰å“åº”ç åˆ†ç»„
        error_codes = Counter(r['responseCode'] for r in error_results)
        
        # æŒ‰æ¥å£åˆ†ç»„
        error_by_endpoint = defaultdict(list)
        for result in error_results:
            error_by_endpoint[result['label']].append(result['responseCode'])
        
        error_patterns = {}
        for endpoint, codes in error_by_endpoint.items():
            error_patterns[endpoint] = dict(Counter(codes))
        
        return {
            'total_errors': len(error_results),
            'error_codes': dict(error_codes),
            'error_by_endpoint': error_patterns
        }
    
    def check_performance_targets(self, stats):
        """æ£€æŸ¥æ€§èƒ½ç›®æ ‡è¾¾æˆæƒ…å†µ"""
        targets = {
            'qps_target': 10000,
            'response_time_target': 500,  # ms
            'availability_target': 99.9   # %
        }
        
        results = {
            'qps_achieved': stats['qps'] >= targets['qps_target'],
            'response_time_achieved': stats['p95_response_time'] <= targets['response_time_target'],
            'availability_achieved': stats['success_rate'] >= targets['availability_target'],
            'targets': targets,
            'actual': {
                'qps': stats['qps'],
                'p95_response_time': stats['p95_response_time'],
                'availability': stats['success_rate']
            }
        }
        
        return results
    
    def generate_recommendations(self, stats, endpoint_analysis, target_check):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # QPSä¼˜åŒ–å»ºè®®
        if not target_check['qps_achieved']:
            recommendations.append({
                'category': 'QPSä¼˜åŒ–',
                'issue': f"å½“å‰QPS {stats['qps']:.2f} æœªè¾¾åˆ°ç›®æ ‡ {target_check['targets']['qps_target']}",
                'suggestions': [
                    'å¢åŠ åº”ç”¨å®ä¾‹æ•°é‡ï¼Œå®ç°æ°´å¹³æ‰©å±•',
                    'ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± é…ç½®',
                    'å¯ç”¨Redisé›†ç¾¤æé«˜ç¼“å­˜æ€§èƒ½',
                    'ä½¿ç”¨å¼‚æ­¥å¤„ç†å‡å°‘é˜»å¡æ“ä½œ',
                    'ä¼˜åŒ–JVMå‚æ•°ï¼Œå¢åŠ å †å†…å­˜'
                ]
            })
        
        # å“åº”æ—¶é—´ä¼˜åŒ–å»ºè®®
        if not target_check['response_time_achieved']:
            recommendations.append({
                'category': 'å“åº”æ—¶é—´ä¼˜åŒ–',
                'issue': f"95%å“åº”æ—¶é—´ {stats['p95_response_time']:.2f}ms è¶…è¿‡ç›®æ ‡ {target_check['targets']['response_time_target']}ms",
                'suggestions': [
                    'å®ç°å¤šçº§ç¼“å­˜ç­–ç•¥ï¼Œæé«˜ç¼“å­˜å‘½ä¸­ç‡',
                    'ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ï¼Œæ·»åŠ å¿…è¦ç´¢å¼•',
                    'ä½¿ç”¨CDNåŠ é€Ÿé™æ€èµ„æº',
                    'å®ç°æ•°æ®åº“è¯»å†™åˆ†ç¦»',
                    'ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦ï¼Œå‡å°‘è®¡ç®—æ—¶é—´'
                ]
            })
        
        # å¯ç”¨æ€§ä¼˜åŒ–å»ºè®®
        if not target_check['availability_achieved']:
            recommendations.append({
                'category': 'å¯ç”¨æ€§ä¼˜åŒ–',
                'issue': f"æˆåŠŸç‡ {stats['success_rate']:.2f}% æœªè¾¾åˆ°ç›®æ ‡ {target_check['targets']['availability_target']}%",
                'suggestions': [
                    'å®ç°æœåŠ¡ç†”æ–­å’Œé™çº§æœºåˆ¶',
                    'å¢åŠ å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨é‡å¯',
                    'å®ç°è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»',
                    'å¢åŠ ç›‘æ§å‘Šè­¦æœºåˆ¶',
                    'ä¼˜åŒ–é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘'
                ]
            })
        
        # æ¥å£ç‰¹å®šå»ºè®®
        for endpoint, analysis in endpoint_analysis.items():
            if analysis['p95_response_time'] > 500:
                recommendations.append({
                    'category': f'{endpoint} æ¥å£ä¼˜åŒ–',
                    'issue': f"æ¥å£å“åº”æ—¶é—´è¿‡é•¿: {analysis['p95_response_time']:.2f}ms",
                    'suggestions': [
                        'æ£€æŸ¥è¯¥æ¥å£çš„ä¸šåŠ¡é€»è¾‘å¤æ‚åº¦',
                        'ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç´¢å¼•',
                        'å®ç°æ¥å£çº§åˆ«çš„ç¼“å­˜',
                        'è€ƒè™‘å¼‚æ­¥å¤„ç†éå…³é”®æ“ä½œ'
                    ]
                })
        
        return recommendations
    
    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
        print("=" * 60)
        print("æ™ºèƒ½å†…å®¹æ¨èå¹³å°æ€§èƒ½æµ‹è¯•åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        print(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æµ‹è¯•æ•°æ®æ–‡ä»¶: {self.jtl_file}")
        print()
        
        # åŸºç¡€ç»Ÿè®¡
        stats = self.calculate_basic_stats()
        print("ğŸ“Š åŸºç¡€æ€§èƒ½æŒ‡æ ‡")
        print("-" * 30)
        print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']:,}")
        print(f"æˆåŠŸè¯·æ±‚æ•°: {stats['success_requests']:,}")
        print(f"å¤±è´¥è¯·æ±‚æ•°: {stats['error_requests']:,}")
        print(f"æˆåŠŸç‡: {stats['success_rate']:.2f}%")
        print(f"QPS: {stats['qps']:.2f}")
        print(f"å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.2f}ms")
        print(f"ä¸­ä½æ•°å“åº”æ—¶é—´: {stats['median_response_time']:.2f}ms")
        print(f"95%å“åº”æ—¶é—´: {stats['p95_response_time']:.2f}ms")
        print(f"99%å“åº”æ—¶é—´: {stats['p99_response_time']:.2f}ms")
        print(f"æœ€å¤§å“åº”æ—¶é—´: {stats['max_response_time']:.2f}ms")
        print()
        
        # æ¥å£åˆ†æ
        endpoint_analysis = self.analyze_by_endpoint()
        print("ğŸ” æ¥å£æ€§èƒ½åˆ†æ")
        print("-" * 30)
        for endpoint, analysis in endpoint_analysis.items():
            print(f"æ¥å£: {endpoint}")
            print(f"  è¯·æ±‚æ•°: {analysis['total_requests']:,}")
            print(f"  æˆåŠŸç‡: {analysis['success_rate']:.2f}%")
            print(f"  å¹³å‡å“åº”æ—¶é—´: {analysis['avg_response_time']:.2f}ms")
            print(f"  95%å“åº”æ—¶é—´: {analysis['p95_response_time']:.2f}ms")
            print()
        
        # é”™è¯¯åˆ†æ
        error_analysis = self.analyze_error_patterns()
        if error_analysis['total_errors'] > 0:
            print("âŒ é”™è¯¯åˆ†æ")
            print("-" * 30)
            print(f"æ€»é”™è¯¯æ•°: {error_analysis['total_errors']:,}")
            print("é”™è¯¯ç åˆ†å¸ƒ:")
            for code, count in error_analysis['error_codes'].items():
                print(f"  {code}: {count:,}")
            print()
        
        # æ€§èƒ½ç›®æ ‡æ£€æŸ¥
        target_check = self.check_performance_targets(stats)
        print("ğŸ¯ æ€§èƒ½ç›®æ ‡è¾¾æˆæƒ…å†µ")
        print("-" * 30)
        print(f"QPSç›®æ ‡ ({target_check['targets']['qps_target']}): {'âœ… è¾¾æˆ' if target_check['qps_achieved'] else 'âŒ æœªè¾¾æˆ'} (å®é™…: {target_check['actual']['qps']:.2f})")
        print(f"å“åº”æ—¶é—´ç›®æ ‡ ({target_check['targets']['response_time_target']}ms): {'âœ… è¾¾æˆ' if target_check['response_time_achieved'] else 'âŒ æœªè¾¾æˆ'} (å®é™…: {target_check['actual']['p95_response_time']:.2f}ms)")
        print(f"å¯ç”¨æ€§ç›®æ ‡ ({target_check['targets']['availability_target']}%): {'âœ… è¾¾æˆ' if target_check['availability_achieved'] else 'âŒ æœªè¾¾æˆ'} (å®é™…: {target_check['actual']['availability']:.2f}%)")
        print()
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = self.generate_recommendations(stats, endpoint_analysis, target_check)
        if recommendations:
            print("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
            print("-" * 30)
            for i, rec in enumerate(recommendations, 1):
                print(f"{i}. {rec['category']}")
                print(f"   é—®é¢˜: {rec['issue']}")
                print("   å»ºè®®:")
                for suggestion in rec['suggestions']:
                    print(f"   - {suggestion}")
                print()
        
        # ä¿å­˜JSONæŠ¥å‘Š
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'basic_stats': stats,
            'endpoint_analysis': endpoint_analysis,
            'error_analysis': error_analysis,
            'target_check': target_check,
            'recommendations': recommendations
        }
        
        report_file = self.jtl_file.replace('.jtl', '_analysis.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        print("=" * 60)

def main():
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 analyze_results.py <jtl_file>")
        sys.exit(1)
    
    jtl_file = sys.argv[1]
    analyzer = PerformanceAnalyzer(jtl_file)
    analyzer.generate_report()

if __name__ == '__main__':
    main()